{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"7t_84Y2liysL"},"outputs":[],"source":["%%capture\n","from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/trading/Momentum Predictor/src\n","\n","%pip install pyts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJbJp6A4i_zL"},"outputs":[],"source":["import numpy as np\n","from helper_config import Config\n","from helper_trainer import train\n","\n","root = '/content/drive/MyDrive/trading/Momentum Predictor'\n","for n_forward in [7, 6, 5, 4, 3, 2, 1]:\n","    for fold in [3]:\n","        print()\n","        print(f'Training for fold {fold} with target lookahead timestep {n_forward}')\n","        config = Config()\n","        config.fold = fold\n","        config.max_len = 256\n","        config.data_dir = f'{root}/data'\n","        config.models_dir = f'{root}/models'\n","        config.model_name = f'pretrained_t3_hslstm4x_t{n_forward}_{config.max_len}'\n","        #config.model_name = f'hslstm4x_t{n_forward}_{config.max_len}'\n","        config.pretrain_config['load_weights_from'] = 'hslstm4x_pretrain_t3_256/model1.pth'\n","        config.train_batch_size = 16\n","        config.valid_batch_size = 128\n","        config.iters_to_accumlate = 4\n","        config.learning_rate = 1e-5\n","        config.num_epochs = 1000\n","        config.n_forward = n_forward\n","        config.num_lstm_layers = 4\n","\n","        config.save_epoch_wait = 1\n","        config.early_stop_count = 20\n","        config.save_checkpoint = True\n","\n","        results = train(config)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}