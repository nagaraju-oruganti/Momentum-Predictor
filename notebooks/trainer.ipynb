{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"7t_84Y2liysL","executionInfo":{"status":"ok","timestamp":1693196782352,"user_tz":-330,"elapsed":17199,"user":{"displayName":"Nagaraju Oruganti","userId":"13872600560951156387"}}},"outputs":[],"source":["%%capture\n","from google.colab import drive\n","drive.flush_and_unmount()\n","drive.mount('/content/drive')\n","\n","#%cd /content/drive/MyDrive/Developer/trading/Momentum Predictor/src\n","#%cd /content/drive/MyDrive/trading/Momentum Predictor/src\n","%cd /content/drive/MyDrive/Momentum Predictor/src\n","\n","%pip install pyts"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cJbJp6A4i_zL"},"outputs":[],"source":["import numpy as np\n","from helper_config import Config\n","from helper_trainer import train\n","\n","#root = '/content/drive/MyDrive/Developer/trading/Momentum Predictor'\n","#root = '/content/drive/MyDrive/trading/Momentum Predictor'\n","root = '/content/drive/MyDrive/Momentum Predictor'\n","for n_forward in [3]:\n","    print()\n","    fold = 1\n","    print(f'Training for fold {fold} with target lookahead timestep {n_forward}')\n","    config                      = Config()\n","    config.fold                 = fold\n","    config.objective_pretrain   = True\n","    config.max_len              = 256\n","    config.data_dir             = f'{root}/data'\n","    config.models_dir           = f'{root}/models'\n","    config.model_name           = f'hslstm4x_1000tics_v3_pretrain_t{n_forward}_{config.max_len}'\n","    config.fine_tune            = False\n","    config.dropout_prob         = 0.3\n","    config.train_on_rmse        = True\n","    config.train_batch_size     = 16            # 16 (finetuning)\n","    config.valid_batch_size     = 32            # 16\n","    config.iters_to_accumlate   = 4\n","    config.learning_rate        = 5e-5\n","    config.num_epochs           = 1000\n","    config.n_forward            = n_forward\n","    config.num_lstm_layers      = 4\n","    config.train_batches        = 5             # 1\n","    config.batch_dir            = '/content/batch_datasets'\n","\n","    config.pretrain_config['load_weights_from'] = None #f'hslstm_pretrain_t7_{config.max_len}/model1.pth'\n","    config.pretrain_config['n_train_tickers']   = 10  # this will be overwritten when using batches\n","    config.pretrain_config['n_valid_tickers']   = 1000\n","\n","    config.save_epoch_wait      = 1\n","    config.early_stop_count     = 10\n","    config.save_checkpoint      = True\n","\n","    results = train(config)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}